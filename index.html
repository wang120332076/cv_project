<!DOCTYPE html>
<html lang="en"><head>  
  <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
  <meta charset="utf-8">
  <title>Categorization and Ingredients Recognition <br>
for Chinese Food | ECE, Virginia Tech | Fall 2017: ECE 5554/4554</title>
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <meta name="description" content="">
  <meta name="author" content="">

<!-- Le styles -->  
  <link href="css/bootstrap.css" rel="stylesheet">
<style>
body {
padding-top: 60px; /* 60px to make the container go all the way to the bottom of the topbar */
}
.vis {
color: #3366CC;
}
.data {
color: #FF9900;
}
</style>
  
<link href="css/bootstrap-responsive.min.css" rel="stylesheet">

<!-- HTML5 shim, for IE6-8 support of HTML5 elements --><!--[if lt IE 9]>
<script src="http://html5shim.googlecode.com/svn/trunk/html5.js"></script>
<![endif]-->
</head>1

<body>
<div class="container">
<div class="page-header">

<!-- Title and Name --> 
<h1>Categorization and Ingredients Recognition <br>
for Chinese Food</h1> 
<span style="font-size: 20px; line-height: 1.5em;"><strong>Chenhao Wang, Mengfan Wang, Yao Xiao, Yuxian Ye</strong></span><br>
<span style="font-size: 18px; line-height: 1.5em;">Fall 2017 ECE 5554/4554 Computer Vision: Class Project</span><br>
<span style="font-size: 18px; line-height: 1.5em;">Virginia Tech</span>
<hr>


<!-- Goal -->
<h3>Abstract</h3>

One or two sentences on the motivation behind the problem you are solving. One or two sentences describing the approach you took. One or two sentences on the main result you obtained.
<br><br>
<!-- figure -->
<h3>Introduction</h3>
Chinese food and it's ingredients are hard to be recognized for several reasons. Firstly, some ingredients are difficult to be recognized, for example, ingredients under soup or sauce. Secondly, they are invisible in flour-made food categories such as dumpling and noodle. Thirdly, many ingredients exhibit large visual variations due to different ways of cutting and cooking. For example, Figure 1 shows six dishes of Chinese food all with pork, though they look totally different. Hence, combing food categorization and ingredients recognition is regarded as a useful method to improve the accuracy.
<br><br>
<!-- Main Illustrative Figure --> 
<div style="text-align: center;">
<img style="height: 200px;" alt="" src="cat.jpg"/>
Figure 1: Different dishes of Chinese food all with pork.
</div>

<br><br>
<!-- Approach -->
<h3>Approach</h3>
<!--Describe very clearly and systematically your approach to solve the problem. Tell us exactly what existing implementations you used to build your system. Tell us what obstacles you faced and how you addressed them. Justify any design choices or judgment calls you made in your approach. -->
<br>
<h4>Dataset: Vireo 172</h4>
Chen J. and her group [1] constructed a Chinese food database: Vireo 172, consisting of 172 categories of food and 110,000 images. It also contains 353 different ingredients labels for each image. All the images in the dataset were crawled from Baidu
and Google image search. The names of food categories, were issued as keywords in Chinese to search engines, and 1,300 images are crawled per food category. Figure 2 shows a part of food categories and the corresponding image.
<div style="text-align: center;">
<img style="height: 370px;" alt="" src="172_1.jpg" align = "center"/>
<br>
Figure 2: 75 kinds of food categories and the corresponding image.
</div>

<h4>CNN Model Architecture Design</h4>
Two CNN models, VGG16[3] and Resnet152[4], are implemented and compared. It's a multiple output task because of the combination of food categorization and ingredients recognition. As a result, the original architecture of VGG16 and Resnet152 need to be modified to apply this case. In terms of design, the major modification is made on the fully connected layers.
For VGG16, the two tasks share the first fc layers and own two privately layers. There are 4,096 neurons for food categorization, and 1024 neurons for ingredient[1]. For Resnet152, because there is only one fc layer, so the two output is connected to the convolution layers (and avg pool) directly[2].

<div style="text-align: center;">
<img style="height: 200px;" alt="" src="vgg16_1.jpg"  align = "center"/>
<img style="height: 200px;" alt="" src='resnet152.jpg' align = "center"/>
<br>Figure 3: The modified architecture of VGG16 and Resnet152.
</div>

<h4>Loss Function</h4>
Relatively, the loss function need to be modified to apply multiple tasks. <br>
For food categorization, the  multinomial logistic loss function is used and defined as <img style="height: 20px;" alt="" src="l1.jpg"  align = "center"/>, while <img style="height: 20px;" alt="" src="l1_1.jpg"  align = "center"/> is the predicted score of an image n for its ground-truth food label y. <img style="height: 20px;" alt="" src="l1_1.jpg"  align = "center"/> is obtained from softmax activation function, so 0 < <img style="height: 20px;" alt="" src="l1_1.jpg"  align = "center"/> < 1. As a result, L1's value is less than 0. The bigger L1's absolute value is, the less probability a image is corresponding to this label. Log function is used for a quicker convergence.<br>
For ingredients recognition, the cross-entropy loss function is used and defined as <img style="height: 47px;" alt="" src="l2.jpg"  align = "center"/>, while <img style="height: 20px;" alt="" src="l2_1.jpg"  align = "center"/> is a vector contains 0 and 1 in 353 dimensions, as the ground-truth ingredients for an image n. <img style="height: 20px;" alt="" src="l2_2.jpg"  align = "center"/> denotes the probability of having ingredient category c for an image n, obtained through sigmoid activation function. So <img style="height: 20px;" alt="" src="l2_2.jpg"  align = "center"/> is also between 0 and 1. Similar to L1, L2 is always below 0, and the higher its absolute value is, the closer it's to the ground-truth.<br>
The overall loss function is defined as <img style="height: 49px;" alt="" src="ls.jpg"  align = "center"/>, combing L1 and L2. <img style="height: 20px;" alt="" src="ls_1.jpg"  align = "center"/> is a parameter used to adjust the importance of food categorization and ingredients recognition. Higher <img style="height: 20px;" alt="" src="ls_1.jpg"  align = "center"/> represents ingredients recognition takes a more importance place in the over loss function. Smaller over function represents better result. The best performance is gotten when <img style="height: 20px;" alt="" src="ls_1.jpg"  align = "center"/> = 0.2 in the practice.


<br><br>
<!-- Results -->
<h3>Results</h3>





<h3>References</h3>
[1] Chen, J., & Ngo, C. W. (2016, October). Deep-based ingredient recognition for cooking recipe retrieval. In Proceedings of the 2016 ACM <i> on Multimedia Conference </i> (pp. 32-41). ACM.
<br>
[2] Salvador, A., Hynes, N., Aytar, Y., Marin, J., Ofli, F., Weber, I., & Torralba, A. (2017). Learning cross-modal embeddings for cooking recipes and food images. In <i>CVPR</i> , (pp. 619-508).
<br>
[3] Simonyan, K., & Zisserman, A. (2014). Very deep convolutional networks for large-scale image recognition. <i>arXiv preprint arXiv:1409.1556.</i>
<br>
[4] He, K., Zhang, X., Ren, S., & Sun, J. (2016). Deep residual learning for image recognition. In <i>CVPR </i> (pp. 770-778).

<br><br><br>
GitHub link: <a href="https://github.com/wang120332076/cv_project">https://github.com/wang120332076/cv_project</a>
  <hr>
  <footer> 
  <p>Â© Chenhao Wang, Mengfan Wang, Yao Xiao, Yuxian Ye</p>
  </footer>
</div>
</div>

<br><br>

</body></html>