<!DOCTYPE html>
<html lang="en"><head>  
  <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
  <meta charset="utf-8">
  <title>Categorization and Ingredients Recognition <br>
for Chinese Food | ECE, Virginia Tech | Fall 2017: ECE 5554/4554</title>
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <meta name="description" content="">
  <meta name="author" content="">

<!-- Le styles -->  
  <link href="css/bootstrap.css" rel="stylesheet">
<style>
body {
padding-top: 60px; /* 60px to make the container go all the way to the bottom of the topbar */
}
.vis {
color: #3366CC;
}
.data {
color: #FF9900;
}
</style>
  
<link href="css/bootstrap-responsive.min.css" rel="stylesheet">

<!-- HTML5 shim, for IE6-8 support of HTML5 elements --><!--[if lt IE 9]>
<script src="http://html5shim.googlecode.com/svn/trunk/html5.js"></script>
<![endif]-->
</head>1

<body>
<div class="container">
<div class="page-header">

<!-- Title and Name --> 
<h1>Categorization and Ingredients Recognition <br>
for Chinese Food</h1> 
<span style="font-size: 20px; line-height: 1.5em;"><strong>Chenhao Wang, Mengfan Wang, Yao Xiao, Yuxian Ye</strong></span><br>
<span style="font-size: 18px; line-height: 1.5em;">Fall 2017 ECE 5554/4554 Computer Vision: Class Project</span><br>
<span style="font-size: 18px; line-height: 1.5em;">Virginia Tech</span>
<hr>


<!-- Goal -->
<h3>Abstract</h3>

One or two sentences on the motivation behind the problem you are solving. One or two sentences describing the approach you took. One or two sentences on the main result you obtained.
<br><br>
<!-- figure -->
<h3>Introduction</h3>
Chinese food and it's ingredients are hard to be recognized for several reasons. Firstly, some ingredients are difficult to be recognized, for example, ingredients under soup or sauce. Secondly, they are invisible in flour-made food categories such as dumpling and noodle. Thirdly, many ingredients exhibit large visual variations due to different ways of cutting and cooking. For example, Figure 1 shows six dishes of Chinese food all with pork, though they look totally different. Hence, combing food categorization and ingredients recognition is regarded as a useful method to improve the accuracy.
<br><br>
<!-- Main Illustrative Figure --> 
<div style="text-align: center;">
<img style="height: 200px;" alt="" src="cat.jpg"/>
Figure 1: Different dishes of Chinese food all with pork.
</div>

<br><br>
<!-- Approach -->
<h3>Approach</h3>
<!--Describe very clearly and systematically your approach to solve the problem. Tell us exactly what existing implementations you used to build your system. Tell us what obstacles you faced and how you addressed them. Justify any design choices or judgment calls you made in your approach. -->
<br>
<h4>Dataset: Vireo 172</h4>
Chen J. and her group [1] constructed a Chinese food database: Vireo 172, consisting of 172 categories of food and 110,000 images. It also contains 353 different ingredients labels for each image. All the images in the dataset were crawled from Baidu
and Google image search. The names of food categories, were issued as keywords in Chinese to search engines, and 1,300 images are crawled per food category. Figure 2 shows a part of food categories and the corresponding image.
<div style="text-align: center;">
<img style="height: 100px;" alt="" src="172.jpg" align = "center"/>
<br>
Figure 2: 75 kinds of food categories and the corresponding image.
</div>

<h4>CNN Model Architecture Design</h4>
Two CNN models, VGG16[3] and Resnet152[4], are implemented and compared. It's a multiple output task because of the combination of food categorization and ingredients recognition. As a result, the original architecture of VGG16 and Resnet152 need to be modified to apply this case. In terms of design, the major modification is made on the fully connected layers.
For VGG16, the two tasks share the first fc layers and own two privately layers. There are 4,096 neurons for food categorization, and 1024 neurons for ingredient[1]. For Resnet152, because there is only one fc layer, so the two output is connected to the convolution layers (and avg pool) directly.

<div style="text-align: center;">
<img style="height: 200px;" alt="" src="vgg16.jpg"  align = "center"/>
<img style="height: 200px;" alt="" src='resnet152.jpg' align = "center"/>
<br>Figure 3: The modified architecture of VGG16 and Resnet152.
</div>

<h4></h4>

<br><br>
<!-- Results -->
<h3>Experiments and results</h3>
Provide details about the experimental set up (number of images/videos, number of datasets you experimented with, train/test split if you used machine learning algorithms, etc.). Describe the evaluation metrics you used to evaluate how well your approach is working. Include clear figures and tables, as well as illustrative qualitative examples if appropriate. Be sure to include obvious baselines to see if your approach is doing better than a naive approach (e.g. for classification accuracy, how well would a classifier do that made random decisions?). Also discuss any parameters of your algorithms, and tell us how you set the values of those parameters. You can also show us how the performance varies as you change those parameter values. Be sure to discuss any trends you see in your results, and explain why these trends make sense. Are the results as expected? Why?

<br><br>

<!-- Main Results Figure --> 
<div style="text-align: center;">
<img style="height: 300px;" alt="" src="results.png">
</div>
<br><br>

<!-- Results -->
<h3>Qualitative results</h3>
Show several visual examples of inputs/outputs of your system (success cases and failures) that help us better understand your approach.
<br><br>

<!-- Main Results Figure --> 
<div style="text-align: center;">
<img style="height: 300px;" alt="" src="qual_results.png">
</div>
<br><br>

<h3>References</h3>
[1] Chen, J., & Ngo, C. W. (2016, October). Deep-based ingredient recognition for cooking recipe retrieval. In Proceedings of the 2016 ACM <i> on Multimedia Conference </i> (pp. 32-41). ACM.
<br>
[2] Salvador, A., Hynes, N., Aytar, Y., Marin, J., Ofli, F., Weber, I., & Torralba, A. (2017). Learning cross-modal embeddings for cooking recipes and food images. In <i>CVPR</i> , (pp. 619-508).
<br>
[3] Simonyan, K., & Zisserman, A. (2014). Very deep convolutional networks for large-scale image recognition. <i>arXiv preprint arXiv:1409.1556.</i>
<br>
[4] He, K., Zhang, X., Ren, S., & Sun, J. (2016). Deep residual learning for image recognition. In <i>CVPR </i> (pp. 770-778).

<br><br><br>
GitHub link: <a href="https://github.com/wang120332076/cv_project">https://github.com/wang120332076/cv_project</a>
  <hr>
  <footer> 
  <p>Â© Chenhao Wang, Mengfan Wang, Yao Xiao, Yuxian Ye</p>
  </footer>
</div>
</div>

<br><br>

</body></html>